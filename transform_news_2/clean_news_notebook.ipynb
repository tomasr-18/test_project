{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_news_from_big_query(table='raw_news', project_id='tomastestproject-433206', dataset='testdb_1') -> pd.DataFrame:\n",
    "    # Set the path to your service account JSON file\n",
    "\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'tomastestproject-433206-adc5bc090976.json'\n",
    "\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "    # Create a BigQuery client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Build your SQL query\n",
    "    query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM `{table_id}`\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the SQL query\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    # Fetch the results\n",
    "    results = query_job.result()\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = results.to_dataframe()\n",
    "\n",
    "    # Check if DataFrame is empty and raise an error if needed\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data found\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    }
   ],
   "source": [
    "df = get_raw_news_from_big_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_news(data: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Förbered DataFrame\n",
    "    # Se till att 'data' kolumnen är en lista av artiklar\n",
    "    df['data'] = df['data'].apply(lambda x: x.get(\n",
    "        'articles', []) if isinstance(x, dict) else [])\n",
    "\n",
    "    # Explodera artiklar till separata rader\n",
    "    df_exploded = df.explode('data')\n",
    "\n",
    "    # Normalisera JSON-data i 'data' kolumnen\n",
    "    articles_df = json_normalize(df_exploded['data'])\n",
    "\n",
    "    # Lägg till övriga kolumner\n",
    "    # Kombinera normaliserad artikeldata med 'company' kolumnen\n",
    "    final_df = pd.concat(\n",
    "        [articles_df, df_exploded[['company']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    final_df.drop(columns=['content', 'source.id', 'urlToImage'], inplace=True)\n",
    "\n",
    "    final_df['publishedAt'] = pd.to_datetime(\n",
    "        final_df['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ', utc=True)\n",
    "\n",
    "    final_df.rename(columns={\"source.name\": \"source_name\",\n",
    "                             \"publishedAt\": \"pub_date\"},\n",
    "                    inplace=True\n",
    "                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score(string: str) -> float:\n",
    "    \"\"\"\n",
    "    Predicts sentiment for a string. returns a float between -1 and 1.\n",
    "    \"\"\"\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    if string is None:\n",
    "        return None\n",
    "    else:\n",
    "        return sia.polarity_scores(string)['compound']\n",
    "\n",
    "\n",
    "def predict_sentiment(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Makes scores for each title and description and aggregates the score for each company for each pub date.\n",
    "    Also adds date of modification as \"fetch_date\".\n",
    "    \"\"\"\n",
    "    df['score_description'] = df['description'].apply(make_score)\n",
    "    df['score_title'] = df['title'].apply(make_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    }
   ],
   "source": [
    "df = get_raw_news_from_big_query()\n",
    "clean_df = clean_news(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tomasrydenstam/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 786 entries, 0 to 785\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   author             776 non-null    object             \n",
      " 1   description        780 non-null    object             \n",
      " 2   pub_date           786 non-null    datetime64[ns, UTC]\n",
      " 3   title              786 non-null    object             \n",
      " 4   url                786 non-null    object             \n",
      " 5   source_name        786 non-null    object             \n",
      " 6   company            786 non-null    object             \n",
      " 7   score_description  780 non-null    float64            \n",
      " 8   score_title        786 non-null    float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), object(6)\n",
      "memory usage: 55.4+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table tomastestproject-433206.testdb_1.clean_news\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Initiera BigQuery-klienten\n",
    "client = bigquery.Client.from_service_account_json(\n",
    "    'tomastestproject-433206-adc5bc090976.json'\n",
    ")\n",
    "\n",
    "# Definiera ditt dataset och tabellnamn\n",
    "table = 'clean_news'\n",
    "table_id = f\"tomastestproject-433206.testdb_1.{table}\"\n",
    "\n",
    "# Definiera schema med uppdaterat kolumnnamn\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"author\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"description\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"pub_date\", \"TIMESTAMP\"),\n",
    "    bigquery.SchemaField(\"title\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"url\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"source_name\", \"STRING\"),  # Uppdaterat kolumnnamn\n",
    "    bigquery.SchemaField(\"company\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"score_description\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"score_title\", \"FLOAT\"),\n",
    "]\n",
    "\n",
    "# Skapa en Tabellreferens\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "\n",
    "# Skapa Tabell\n",
    "table = client.create_table(table)  # Här skapas tabellen med table-objektet\n",
    "print(f\"Created table {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def write_clean_news_to_bq(data: pd.DataFrame, table='clean_news', project_id='tomastestproject-433206', dataset='testdb_1'):\n",
    "    # Initiera BigQuery-klienten\n",
    "    client = bigquery.Client.from_service_account_json(\n",
    "        'tomastestproject-433206-adc5bc090976.json'\n",
    "    )\n",
    "\n",
    "    # Definiera fullständigt tabell-id\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "\n",
    "    # Ladda DataFrame till BigQuery\n",
    "    job = client.load_table_from_dataframe(data, table_id)\n",
    "\n",
    "    # Vänta tills jobbet är klart\n",
    "    job.result()\n",
    "\n",
    "    # Kontrollera om det blev fel vid insättning av rader\n",
    "    if job.errors:\n",
    "        print(f\"Errors: {job.errors}\")\n",
    "    else:\n",
    "        print(\"DataFrame har sparats till BigQuery utan fel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_raw_news_from_big_query(table='raw_news', project_id='tomastestproject-433206', dataset='testdb_1'):\n",
    "    \"\"\"\n",
    "    Fetches unprocessed raw news data from a specified BigQuery table and returns it as a pandas DataFrame \n",
    "    along with a string of row IDs that were used.\n",
    "\n",
    "    This function connects to Google BigQuery using credentials from a service account, constructs and executes \n",
    "    an SQL query to select rows where `is_processed` is FALSE from the specified table within the provided \n",
    "    dataset and project. The results are returned as a pandas DataFrame. It also extracts the `unique_id` from \n",
    "    the DataFrame and compiles them into a comma-separated string format for further processing.\n",
    "\n",
    "    Args:\n",
    "        table (str): The name of the table in BigQuery to fetch data from. Default is 'raw_news'.\n",
    "        project_id (str): The Google Cloud project ID where the BigQuery dataset is located. Default is 'tomastestproject-433206'.\n",
    "        dataset (str): The BigQuery dataset name that contains the table. Default is 'testdb_1'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the unprocessed raw news data.\n",
    "        str: A string of `unique_id`s from the fetched rows, formatted as comma-separated values in single quotes.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no unprocessed data is found in the table.\n",
    "    \"\"\"\n",
    "    # secret_data = get_secret()\n",
    "\n",
    "    # # Ladda JSON-strängen till en dictionary\n",
    "    # service_account_info = json.loads(secret_data)\n",
    "\n",
    "    # # Initiera BigQuery-klienten med service account\n",
    "    # client = bigquery.Client.from_service_account_info(service_account_info)\n",
    "    client = bigquery.Client.from_service_account_json(\n",
    "        'tomastestproject-433206-adc5bc090976.json'\n",
    "    )\n",
    "\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "\n",
    "    # Build your SQL query\n",
    "    query = f\"\"\"\n",
    "        SELECT unique_id, data,company\n",
    "        FROM `{table_id}`\n",
    "        WHERE is_processed IS FALSE\n",
    "        \"\"\"\n",
    "\n",
    "    # Execute the SQL query\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    # Fetch the results\n",
    "    results = query_job.result()\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = results.to_dataframe()\n",
    "\n",
    "    # Check if DataFrame is empty and raise an error if needed\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No unprocessed data found\")\n",
    "\n",
    "    # Create a comma-separated string of unique IDs\n",
    "    processed_id_list = df[\"unique_id\"].to_list()\n",
    "    id_str = ', '.join(f\"'{id}'\" for id in processed_id_list)\n",
    "\n",
    "    return df, id_str\n",
    "\n",
    "\n",
    "def update_is_processed(id_string: str, table='raw_news', project_id='tomastestproject-433206', dataset='testdb_1'):\n",
    "\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "    # secret_data = get_secret()\n",
    "\n",
    "    # # Ladda JSON-strängen till en dictionary\n",
    "    # service_account_info = json.loads(secret_data)\n",
    "\n",
    "    # # Initiera BigQuery-klienten med service account\n",
    "    # client = bigquery.Client.from_service_account_info(\n",
    "    #     service_account_info)\n",
    "\n",
    "    client = bigquery.Client.from_service_account_json(\n",
    "        'tomastestproject-433206-adc5bc090976.json'\n",
    "    )\n",
    "\n",
    "    # Konstruera SQL-frågan\n",
    "    query = f\"\"\"\n",
    "    UPDATE `{table_id}`\n",
    "    SET is_processed = TRUE\n",
    "    WHERE unique_id IN ({id_string});\n",
    "    \"\"\"\n",
    "\n",
    "    # Kör frågan\n",
    "    job = client.query(query)\n",
    "    job.result()  # Vänta på att jobbet ska slutföras\n",
    "\n",
    "\n",
    "def clean_news(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Cleans and transforms raw news data extracted from BigQuery into a structured DataFrame format.\n",
    "\n",
    "    This function takes a DataFrame containing raw news data, unpacks JSON-like structures to separate rows \n",
    "    for each news article, and normalizes the data into a flat table format. The resulting DataFrame will have \n",
    "    one row per article with relevant information such as author, description, publication date, title, URL, \n",
    "    source, company, and sentiment scores.\n",
    "\n",
    "    \"\"\"\n",
    "    # Förbered DataFrame\n",
    "    # Se till att 'data' kolumnen är en lista av artiklar\n",
    "    df.drop(columns=['unique_id'], inplace=True)\n",
    "    df['data'] = df['data'].apply(lambda x: x.get(\n",
    "        'articles', []) if isinstance(x, dict) else [])\n",
    "\n",
    "    # Explodera artiklar till separata rader\n",
    "    df_exploded = df.explode('data')\n",
    "\n",
    "    # Normalisera JSON-data i 'data' kolumnen\n",
    "    articles_df = pd.json_normalize(df_exploded['data'])\n",
    "\n",
    "    # Lägg till övriga kolumner\n",
    "    # Kombinera normaliserad artikeldata med 'company' kolumnen\n",
    "    final_df = pd.concat(\n",
    "        [articles_df, df_exploded[['company']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    final_df.drop(columns=['content', 'source.id', 'urlToImage'], inplace=True)\n",
    "\n",
    "    final_df['publishedAt'] = pd.to_datetime(\n",
    "        final_df['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ', utc=True)\n",
    "\n",
    "    final_df.rename(columns={\"source.name\": \"source_name\",\n",
    "                             \"publishedAt\": \"pub_date\"},\n",
    "                    inplace=True\n",
    "                    )\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def make_sentiment_score(string: str) -> float:\n",
    "    \"\"\"\n",
    "    Predicts sentiment for a string. returns a float between -1 and 1.\n",
    "    \"\"\"\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    if string is None:\n",
    "        return None\n",
    "    else:\n",
    "        return sia.polarity_scores(string)['compound']\n",
    "\n",
    "\n",
    "def predict_sentiment(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Makes scores for each title and description and adds it as \"score_description\" and \"score_title\" to the Dataframe.\n",
    "    \"\"\"\n",
    "    df['score_description'] = df['description'].apply(make_sentiment_score)\n",
    "    df['score_title'] = df['title'].apply(make_sentiment_score)\n",
    "\n",
    "\n",
    "def write_clean_news_to_bq(data: pd.DataFrame, table='clean_news', project_id='tomastestproject-433206', dataset='testdb_1'):\n",
    "    \"\"\"\n",
    "    Writes cleaned data to Big Query\n",
    "    \"\"\"\n",
    "    # # Initiera BigQuery-klienten\n",
    "    # secret_data = get_secret()\n",
    "\n",
    "    # # Ladda JSON-strängen till en dictionary\n",
    "    # service_account_info = json.loads(secret_data)\n",
    "\n",
    "    # # Initiera BigQuery-klienten med service account\n",
    "    # client = bigquery.Client.from_service_account_info(\n",
    "    #     service_account_info)\n",
    "    client = bigquery.Client.from_service_account_json(\n",
    "        'tomastestproject-433206-adc5bc090976.json'\n",
    "    )\n",
    "\n",
    "    # Definiera fullständigt tabell-id\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "\n",
    "    # Ladda DataFrame till BigQuery\n",
    "    job = client.load_table_from_dataframe(data, table_id)\n",
    "\n",
    "    # Vänta tills jobbet är klart\n",
    "    job.result()\n",
    "\n",
    "    # Kontrollera om det blev fel vid insättning av rader\n",
    "    if job.errors:\n",
    "        print(f\"Errors: {job.errors}\")\n",
    "    else:\n",
    "        return f'{job.output_rows} rader sparades till {table}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    }
   ],
   "source": [
    "df, ids = get_raw_news_from_big_query(\n",
    "    table='raw_news_with_uuid', project_id='tomastestproject-433206', dataset='testdb_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>data</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>476e0453-2746-4128-afef-89cb2f6c162b</td>\n",
       "      <td>{'articles': [{'author': 'applech2', 'content'...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2260b501-7b08-4807-94a5-dfedce28dde4</td>\n",
       "      <td>{'articles': [{'author': 'applech2', 'content'...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>981f711c-dacc-4126-bc9e-4b9678ea9f76</td>\n",
       "      <td>{'articles': [{'author': 'applech2', 'content'...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>058ab43e-c98f-4923-9635-32d03682a194</td>\n",
       "      <td>{'articles': [{'author': 'applech2', 'content'...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954ea9f-280b-4433-8707-75cfa8659c73</td>\n",
       "      <td>{'articles': [{'author': 'applech2', 'content'...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>46470d40-5be1-4daa-8a38-e20a463c5749</td>\n",
       "      <td>{'articles': [{'author': 'William Gavin', 'con...</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>dfb0f8bd-cc24-4250-aa84-f45832300251</td>\n",
       "      <td>{'articles': [{'author': 'Ana Altchek', 'conte...</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ad4294b9-9cf1-45d0-9bea-84abf081544a</td>\n",
       "      <td>{'articles': [{'author': 'Ana Altchek', 'conte...</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>abf0a84b-d8f0-46ad-9a2d-cb671b07fb8c</td>\n",
       "      <td>{'articles': [{'author': 'Bradley Brownell', '...</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6af3087a-f252-46f0-9d29-4543bf81c804</td>\n",
       "      <td>{'articles': [{'author': 'Bradley Brownell', '...</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_id  \\\n",
       "0    476e0453-2746-4128-afef-89cb2f6c162b   \n",
       "1    2260b501-7b08-4807-94a5-dfedce28dde4   \n",
       "2    981f711c-dacc-4126-bc9e-4b9678ea9f76   \n",
       "3    058ab43e-c98f-4923-9635-32d03682a194   \n",
       "4    1954ea9f-280b-4433-8707-75cfa8659c73   \n",
       "..                                    ...   \n",
       "99   46470d40-5be1-4daa-8a38-e20a463c5749   \n",
       "100  dfb0f8bd-cc24-4250-aa84-f45832300251   \n",
       "101  ad4294b9-9cf1-45d0-9bea-84abf081544a   \n",
       "102  abf0a84b-d8f0-46ad-9a2d-cb671b07fb8c   \n",
       "103  6af3087a-f252-46f0-9d29-4543bf81c804   \n",
       "\n",
       "                                                  data company  \n",
       "0    {'articles': [{'author': 'applech2', 'content'...    AAPL  \n",
       "1    {'articles': [{'author': 'applech2', 'content'...    AAPL  \n",
       "2    {'articles': [{'author': 'applech2', 'content'...    AAPL  \n",
       "3    {'articles': [{'author': 'applech2', 'content'...    AAPL  \n",
       "4    {'articles': [{'author': 'applech2', 'content'...    AAPL  \n",
       "..                                                 ...     ...  \n",
       "99   {'articles': [{'author': 'William Gavin', 'con...    TSLA  \n",
       "100  {'articles': [{'author': 'Ana Altchek', 'conte...    TSLA  \n",
       "101  {'articles': [{'author': 'Ana Altchek', 'conte...    TSLA  \n",
       "102  {'articles': [{'author': 'Bradley Brownell', '...    TSLA  \n",
       "103  {'articles': [{'author': 'Bradley Brownell', '...    TSLA  \n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Rensa nyhetsdata\n",
    "cleaned_df = clean_news(df=df)\n",
    "\n",
    "# Gör sentimentanalyser\n",
    "predict_sentiment(df=cleaned_df)\n",
    "\n",
    "# Skriv de rensade nyheterna till BigQuery och få antalet rader som skrevs\n",
    "rows_written = write_clean_news_to_bq(data=cleaned_df, table='clean_news_copy')\n",
    "\n",
    "update_is_processed(id_string=ids, table='raw_news_with_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame har sparats till BigQuery utan fel.\n"
     ]
    }
   ],
   "source": [
    "write_clean_news_to_bq(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORTSÄTT HÄR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              unique_id  \\\n",
      "0  142a1c6c-4943-452a-8d09-46d3d61007bf   \n",
      "1  ec82340a-3a50-4e7d-af11-2f78b2878dbc   \n",
      "2  1983a15a-e23b-481c-98d6-0785ae1358e3   \n",
      "3  7ec7b81a-a5d6-4ef8-8d8e-fe68b212870c   \n",
      "4  de325a15-d2ca-4703-b459-7824fb59dada   \n",
      "\n",
      "                                                data  \n",
      "0  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "1  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "2  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "3  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "4  {'articles': [{'author': None, 'content': 'Pos...  \n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd  # Importera pandas för att hantera DataFrames\n",
    "\n",
    "# Initialisera BigQuery-klienten\n",
    "client = bigquery.Client.from_service_account_json(\n",
    "    'tomastestproject-433206-adc5bc090976.json')\n",
    "\n",
    "# SQL-fråga för att hämta data från tabellen\n",
    "query = \"\"\" \n",
    "SELECT unique_id, data \n",
    "FROM `tomastestproject-433206.testdb_1.raw_news_with_uuid`\n",
    "WHERE is_processed IS FALSE\n",
    "\"\"\"\n",
    "\n",
    "# Kör frågan\n",
    "job = client.query(query)\n",
    "\n",
    "# Vänta på att jobbet ska slutföras och hämta resultaten som en DataFrame\n",
    "df = job.to_dataframe()\n",
    "\n",
    "# Visa de första raderna i DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_id_list = df[\"unique_id\"].to_list()\n",
    "id_str = ', '.join(f\"'{id}'\" for id in processed_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabellen har uppdaterats med is_processed = TRUE för angivna ID:n.\n"
     ]
    }
   ],
   "source": [
    "# Konvertera listan till en SQL-kompatibel sträng\n",
    "id_str = ', '.join(f\"'{id}'\" for id in processed_id_list)\n",
    "\n",
    "# Konstruera SQL-frågan\n",
    "query = f\"\"\"\n",
    "UPDATE `tomastestproject-433206.testdb_1.raw_news_with_uuid`\n",
    "SET is_processed = TRUE\n",
    "WHERE unique_id IN ({id_str});\n",
    "\"\"\"\n",
    "\n",
    "# Kör frågan\n",
    "job = client.query(query)\n",
    "job.result()  # Vänta på att jobbet ska slutföras\n",
    "\n",
    "print(\"Tabellen har uppdaterats med is_processed = TRUE för angivna ID:n.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_news_from_big_query(table='raw_news', project_id='tomastestproject-433206', dataset='testdb_1'):\n",
    "    \"\"\"\n",
    "    Fetches unprocessed raw news data from a specified BigQuery table and returns it as a pandas DataFrame \n",
    "    along with a string of row IDs that were used.\n",
    "\n",
    "    This function connects to Google BigQuery using credentials from a service account, constructs and executes \n",
    "    an SQL query to select rows where `is_processed` is FALSE from the specified table within the provided \n",
    "    dataset and project. The results are returned as a pandas DataFrame. It also extracts the `unique_id` from \n",
    "    the DataFrame and compiles them into a comma-separated string format for further processing.\n",
    "\n",
    "    Args:\n",
    "        table (str): The name of the table in BigQuery to fetch data from. Default is 'raw_news'.\n",
    "        project_id (str): The Google Cloud project ID where the BigQuery dataset is located. Default is 'tomastestproject-433206'.\n",
    "        dataset (str): The BigQuery dataset name that contains the table. Default is 'testdb_1'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the unprocessed raw news data.\n",
    "        str: A string of `unique_id`s from the fetched rows, formatted as comma-separated values in single quotes.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no unprocessed data is found in the table.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initiera BigQuery-klienten med service account\n",
    "    client = bigquery.Client.from_service_account_json(\n",
    "        '/Users/tomasrydenstam/Desktop/Skola/test_project/transform_news_2/tomastestproject-433206-adc5bc090976.json')\n",
    "\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "\n",
    "    # Build your SQL query\n",
    "    query = f\"\"\"\n",
    "        SELECT unique_id, data\n",
    "        FROM `{table_id}`\n",
    "        WHERE is_processed IS FALSE\n",
    "        \"\"\"\n",
    "\n",
    "    # Execute the SQL query\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    # Fetch the results\n",
    "    results = query_job.result()\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = results.to_dataframe()\n",
    "\n",
    "    # Check if DataFrame is empty and raise an error if needed\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No unprocessed data found\")\n",
    "\n",
    "    # Create a comma-separated string of unique IDs\n",
    "    processed_id_list = df[\"unique_id\"].to_list()\n",
    "    if processed_id_list:\n",
    "        id_str = ', '.join(f\"'{id}'\" for id in processed_id_list)\n",
    "\n",
    "    return df, id_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_is_processed(id_string: str, table='raw_news', project_id='tomastestproject-433206', dataset='testdb_1'):\n",
    "\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "    client = bigquery.Client.from_service_account_json(\n",
    "        '/Users/tomasrydenstam/Desktop/Skola/test_project/transform_news_2/tomastestproject-433206-adc5bc090976.json')\n",
    "\n",
    "    # Konstruera SQL-frågan\n",
    "    query = f\"\"\"\n",
    "    UPDATE `{table_id}`\n",
    "    SET is_processed = TRUE\n",
    "    WHERE unique_id IN ({id_string});\n",
    "    \"\"\"\n",
    "\n",
    "    # Kör frågan\n",
    "    job = client.query(query)\n",
    "    job.result()  # Vänta på att jobbet ska slutföras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    }
   ],
   "source": [
    "df, stttrr = get_raw_news_from_big_query(table='raw_news_with_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'476e0453-2746-4128-afef-89cb2f6c162b', '2260b501-7b08-4807-94a5-dfedce28dde4', 'b0138e6e-e669-4624-8254-f9351405b773', '981f711c-dacc-4126-bc9e-4b9678ea9f76', '1954ea9f-280b-4433-8707-75cfa8659c73', '058ab43e-c98f-4923-9635-32d03682a194', 'e3147755-c6d1-4b1f-b74e-b962b37dcdfc', '6036c725-5fea-4e50-9ce3-f743446be23d', 'd3059d6a-1d57-4315-9f74-13968e13b3fa', '887e0e21-1fdd-44ab-a64d-6f1bbd78fa01', 'c5564d54-7a41-466b-a428-0df6dd00fde4', '2e3d4551-0fe0-4703-96a7-58d0d0000bd6', '1bea4b39-27d0-4616-91da-8b3ce929bd4f', '8a8dd974-b83f-4714-b40e-0b562d410645', '33bb229d-f0f9-4854-a313-277334e1bd30', '8a3f901a-ad64-4e0d-8a0f-9171289f636f', '33449269-5bb4-4c8e-9200-92a392c5e24b', '53849022-af6b-4b6e-b5b8-9e764ec32d5d', 'ea1669f8-8a08-4803-a4fb-3730062189ad', '13bfd93f-bbed-43c4-8d8b-9436cb8b004a', '5008cc35-eb61-4349-9a78-f47bb6e60007', '5f393783-961e-46a2-a91d-8ff954e7967e', '6a6264e0-c982-4ee4-aab2-1fa61cc20d3e', '602f0d69-93b2-425c-a835-1953ce87a209', '356d69da-4484-4fff-8053-edb37d288f27', 'df5c8647-92b1-40dd-9abc-452a3569eab0', 'da64b3ff-e4ae-45ef-8796-a8183257c9f7', 'a8f8f267-ef60-4c28-947f-7542eb6b6bae', '0bd61459-c57b-43ff-9698-29904108b7e3', '290d11c5-4ebf-4ff4-acac-6774bff728d2', '4243b8fa-cc1d-4248-8a28-7a0331bc266a', 'de325a15-d2ca-4703-b459-7824fb59dada', '77d108b9-13de-4bd4-8b21-888965e696c1', '5e8370fa-a6e8-43e4-b193-5a97bce69127', '42c1d17b-71fd-4c82-9e1d-6df19fb2b5a7', '5cce3995-7403-4e8b-b792-78b91968b080', '2a9a62d6-1631-4b36-9edb-034d91013519', '64189027-957d-42ca-b49a-46ae57313c90', 'ae74f4f8-3941-4643-8bac-c639dcf1d644', '6a76e9e2-fde3-4919-baea-a969632aeb24', '7e67715a-a062-46e6-a730-9c1cf72922c3', '24e3fefb-42c2-4014-87c1-21946e7eecf1', '9d228ffb-88b8-413f-bfe0-131fa4551356', 'bf96a12a-9e26-469c-9908-8737f506d4f9', 'fe18ba3e-a994-4db4-bffd-df0ba5e3c878', '0fcb1b75-4ccd-44f0-8e2f-bfaa574f776a', 'bdf53115-8b81-4f4a-aea7-1850163f6ca4', 'bca0699f-022e-4ae4-8d4e-71a213089a01', 'a001e773-8b41-45a3-a22a-99f202035c65', '6bac97c7-7cf6-4caa-91c8-44ede08e0f84', '2bbe0a87-8396-4b50-ba7c-b551bdca86c6', '1aa72a79-1db7-4613-8741-978c20aecc68', 'ef66c776-7728-4fdd-bfd0-66bd79d603ea', 'b4968a27-c406-41d3-9e6b-863ba9f0127a', '1756b196-0382-4d09-b9d4-04c4c1da3c1f', 'c4c7e605-8b5e-426c-9fa1-58926708d65e', 'ef610a1d-3ed0-4d20-86bd-0e698800120f', '3bb75076-9c30-442f-8c24-4bd54f0735b6', 'e12b32bc-5136-484d-9af7-7377c9ac4dd0', 'c8b65ad4-84c9-4a4f-bfea-5894ecbb877a', '17bb3534-a028-4328-9f09-3773f999d63d', '1c0cdc69-dc84-4d4b-9761-0d9a6c1df98a', 'd34ab95f-17a4-4b96-84d7-665b6a78adf7', '71647a2e-3b25-4eab-9e9b-3a2dac5459fb', '2ebb63a7-1265-41e1-9935-d8ef8cddd67d', 'f782be92-da33-45e9-9823-b297abdf0d01', 'e19b4ff5-778f-418f-9a89-873e591e32a5', 'ebe68a72-35fa-4a5d-8ac4-1cb4a11d36a4', 'cf18e3d0-848b-42b6-94a0-27d0cba8cc52', '56304256-12b8-4663-8284-ebe6d972fc80', '32854369-0afb-470b-b897-e627119225df', 'ae874bfd-df75-475b-8e2f-97bccb930841', '142a1c6c-4943-452a-8d09-46d3d61007bf', '1983a15a-e23b-481c-98d6-0785ae1358e3', 'ec82340a-3a50-4e7d-af11-2f78b2878dbc', '7ec7b81a-a5d6-4ef8-8d8e-fe68b212870c', 'e413e8b4-4a21-4e54-8eb9-fc62e0c02e5e', 'ef45cf67-2756-4483-b657-56d9bd6d8078', 'efe49055-b216-4c20-92f2-37cc665550c7', 'a50cc5a6-ec51-40ac-9a7b-3443e27ced77', 'c261c39b-ea61-443b-a857-acb176dbda13', '94ad3352-3e79-41ba-98e5-865205acd93b', 'c93f7a15-6862-4c96-a9b2-24bb39d584f3', 'd27e8cbc-71ec-4f13-a012-5de6a12db476', '41b1680c-14de-4553-a272-3d6d949f7bfd', 'f67b845a-c362-49a9-910b-33cf52a61b47', '96922671-3a47-4b5c-8325-d046e0cfbe03', 'c9e3dba3-0b5a-475c-a488-414996f4dac0', 'e958eacd-222e-4384-8c53-4e02e25efc19', 'ff86f9e0-c866-4bc6-939f-72357117b6d3', '755f15eb-852b-4e27-b550-57e28394de80', '96fc437e-198a-49dd-9249-27dec1c0dab4', 'ca1e4ed7-ff0b-46d5-b4ad-58debfae7b11', '565140ff-4469-4c00-96da-45ef8b321ef7', 'b6c6d1ce-7f6d-46d7-a349-6502f3b156c6', '03292e46-483f-49c0-b8e6-4cebc1655fd1', '55794141-47f3-4a56-929d-f1643ad16293', '527da5a4-d5c9-4806-ac56-8c719288d6ec', 'bc448599-4b7d-4a88-ac3e-158bbaf0dcaf', '46470d40-5be1-4daa-8a38-e20a463c5749', 'dfb0f8bd-cc24-4250-aa84-f45832300251', 'ad4294b9-9cf1-45d0-9bea-84abf081544a', 'abf0a84b-d8f0-46ad-9a2d-cb671b07fb8c', '6af3087a-f252-46f0-9d29-4543bf81c804'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stttrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_is_processed(id_string=stttrr, table='raw_news_with_uuid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
