{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_news_from_big_query(table='raw_news', project_id='tomastestproject-433206', dataset='testdb_1') -> pd.DataFrame:\n",
    "    # Set the path to your service account JSON file\n",
    "\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'tomastestproject-433206-adc5bc090976.json'\n",
    "\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "    # Create a BigQuery client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Build your SQL query\n",
    "    query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM `{table_id}`\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the SQL query\n",
    "    query_job = client.query(query)\n",
    "\n",
    "    # Fetch the results\n",
    "    results = query_job.result()\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    df = results.to_dataframe()\n",
    "\n",
    "    # Check if DataFrame is empty and raise an error if needed\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data found\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    }
   ],
   "source": [
    "df = get_raw_news_from_big_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_news(data: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Förbered DataFrame\n",
    "    # Se till att 'data' kolumnen är en lista av artiklar\n",
    "    df['data'] = df['data'].apply(lambda x: x.get(\n",
    "        'articles', []) if isinstance(x, dict) else [])\n",
    "\n",
    "    # Explodera artiklar till separata rader\n",
    "    df_exploded = df.explode('data')\n",
    "\n",
    "    # Normalisera JSON-data i 'data' kolumnen\n",
    "    articles_df = json_normalize(df_exploded['data'])\n",
    "\n",
    "    # Lägg till övriga kolumner\n",
    "    # Kombinera normaliserad artikeldata med 'company' kolumnen\n",
    "    final_df = pd.concat(\n",
    "        [articles_df, df_exploded[['company']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "    final_df.drop(columns=['content', 'source.id', 'urlToImage'], inplace=True)\n",
    "\n",
    "    final_df['publishedAt'] = pd.to_datetime(\n",
    "        final_df['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ', utc=True)\n",
    "\n",
    "    final_df.rename(columns={\"source.name\": \"source_name\",\n",
    "                             \"publishedAt\": \"pub_date\"},\n",
    "                    inplace=True\n",
    "                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score(string: str) -> float:\n",
    "    \"\"\"\n",
    "    Predicts sentiment for a string. returns a float between -1 and 1.\n",
    "    \"\"\"\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    if string is None:\n",
    "        return None\n",
    "    else:\n",
    "        return sia.polarity_scores(string)['compound']\n",
    "\n",
    "\n",
    "def predict_sentiment(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Makes scores for each title and description and aggregates the score for each company for each pub date.\n",
    "    Also adds date of modification as \"fetch_date\".\n",
    "    \"\"\"\n",
    "    df['score_description'] = df['description'].apply(make_score)\n",
    "    df['score_title'] = df['title'].apply(make_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    }
   ],
   "source": [
    "df = get_raw_news_from_big_query()\n",
    "clean_df = clean_news(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tomasrydenstam/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 786 entries, 0 to 785\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   author             776 non-null    object             \n",
      " 1   description        780 non-null    object             \n",
      " 2   pub_date           786 non-null    datetime64[ns, UTC]\n",
      " 3   title              786 non-null    object             \n",
      " 4   url                786 non-null    object             \n",
      " 5   source_name        786 non-null    object             \n",
      " 6   company            786 non-null    object             \n",
      " 7   score_description  780 non-null    float64            \n",
      " 8   score_title        786 non-null    float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), object(6)\n",
      "memory usage: 55.4+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table tomastestproject-433206.testdb_1.clean_news\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Initiera BigQuery-klienten\n",
    "client = bigquery.Client.from_service_account_json(\n",
    "    'tomastestproject-433206-adc5bc090976.json'\n",
    ")\n",
    "\n",
    "# Definiera ditt dataset och tabellnamn\n",
    "table = 'clean_news'\n",
    "table_id = f\"tomastestproject-433206.testdb_1.{table}\"\n",
    "\n",
    "# Definiera schema med uppdaterat kolumnnamn\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"author\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"description\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"pub_date\", \"TIMESTAMP\"),\n",
    "    bigquery.SchemaField(\"title\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"url\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"source_name\", \"STRING\"),  # Uppdaterat kolumnnamn\n",
    "    bigquery.SchemaField(\"company\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"score_description\", \"FLOAT\"),\n",
    "    bigquery.SchemaField(\"score_title\", \"FLOAT\"),\n",
    "]\n",
    "\n",
    "# Skapa en Tabellreferens\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "\n",
    "# Skapa Tabell\n",
    "table = client.create_table(table)  # Här skapas tabellen med table-objektet\n",
    "print(f\"Created table {table_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def write_clean_news_to_bq(data: pd.DataFrame, table='clean_news', project_id='tomastestproject-433206', dataset='testdb_1'):\n",
    "    # Initiera BigQuery-klienten\n",
    "    client = bigquery.Client.from_service_account_json(\n",
    "        'tomastestproject-433206-adc5bc090976.json'\n",
    "    )\n",
    "\n",
    "    # Definiera fullständigt tabell-id\n",
    "    table_id = f\"{project_id}.{dataset}.{table}\"\n",
    "\n",
    "    # Ladda DataFrame till BigQuery\n",
    "    job = client.load_table_from_dataframe(data, table_id)\n",
    "\n",
    "    # Vänta tills jobbet är klart\n",
    "    job.result()\n",
    "\n",
    "    # Kontrollera om det blev fel vid insättning av rader\n",
    "    if job.errors:\n",
    "        print(f\"Errors: {job.errors}\")\n",
    "    else:\n",
    "        print(\"DataFrame har sparats till BigQuery utan fel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'description', 'publishedAt', 'title', 'url', 'source.name',\n",
       "       'company', 'score_description', 'score_title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame har sparats till BigQuery utan fel.\n"
     ]
    }
   ],
   "source": [
    "write_clean_news_to_bq(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORTSÄTT HÄR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "/Users/tomasrydenstam/Desktop/Skola/test_project/testv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:207: UserWarning: Unable to determine type for field 'data'.\n",
      "  warnings.warn(\"Unable to determine type for field '{}'.\".format(bq_field.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              unique_id  \\\n",
      "0  142a1c6c-4943-452a-8d09-46d3d61007bf   \n",
      "1  ec82340a-3a50-4e7d-af11-2f78b2878dbc   \n",
      "2  1983a15a-e23b-481c-98d6-0785ae1358e3   \n",
      "3  7ec7b81a-a5d6-4ef8-8d8e-fe68b212870c   \n",
      "4  de325a15-d2ca-4703-b459-7824fb59dada   \n",
      "\n",
      "                                                data  \n",
      "0  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "1  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "2  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "3  {'articles': [{'author': 'Trefis Team, Contrib...  \n",
      "4  {'articles': [{'author': None, 'content': 'Pos...  \n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd  # Importera pandas för att hantera DataFrames\n",
    "\n",
    "# Initialisera BigQuery-klienten\n",
    "client = bigquery.Client.from_service_account_json(\n",
    "    'tomastestproject-433206-adc5bc090976.json')\n",
    "\n",
    "# SQL-fråga för att hämta data från tabellen\n",
    "query = \"\"\" \n",
    "SELECT unique_id, data \n",
    "FROM `tomastestproject-433206.testdb_1.raw_news_with_uuid`\n",
    "WHERE is_processed IS FALSE\n",
    "\"\"\"\n",
    "\n",
    "# Kör frågan\n",
    "job = client.query(query)\n",
    "\n",
    "# Vänta på att jobbet ska slutföras och hämta resultaten som en DataFrame\n",
    "df = job.to_dataframe()\n",
    "\n",
    "# Visa de första raderna i DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_id_list = df[\"unique_id\"].to_list()\n",
    "id_str = ', '.join(f\"'{id}'\" for id in processed_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabellen har uppdaterats med is_processed = TRUE för angivna ID:n.\n"
     ]
    }
   ],
   "source": [
    "# Konvertera listan till en SQL-kompatibel sträng\n",
    "id_str = ', '.join(f\"'{id}'\" for id in processed_id_list)\n",
    "\n",
    "# Konstruera SQL-frågan\n",
    "query = f\"\"\"\n",
    "UPDATE `tomastestproject-433206.testdb_1.raw_news_with_uuid`\n",
    "SET is_processed = TRUE\n",
    "WHERE unique_id IN ({id_str});\n",
    "\"\"\"\n",
    "\n",
    "# Kör frågan\n",
    "job = client.query(query)\n",
    "job.result()  # Vänta på att jobbet ska slutföras\n",
    "\n",
    "print(\"Tabellen har uppdaterats med is_processed = TRUE för angivna ID:n.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
